{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When should `AwkwardInputLayer`'s number of partitions be updated?\n",
    "\n",
    "We have an `AwkwardInputLayer` that has 10 partitions - but we don't know that till late in the game. So lets start with a single partition, and then update it when the user calls `.compute()` on the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_awkward as dak\n",
    "import awkward as ak\n",
    "import dask\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Layer\n",
    "\n",
    "The function that will generate the data - it is dead simple as it always returns the same data (but _pretend_!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(i_partition: int) -> ak.Array:\n",
    "    '''Generate the data for a particular partition. There is always one\n",
    "    file per partition.\n",
    "\n",
    "    Use a file that is from an actual SX query, and has \"JetPt' in it.\n",
    "\n",
    "    Args:\n",
    "        block (int): The block number\n",
    "    '''\n",
    "    print(f\"Loading data for partition {i_partition}\")\n",
    "    filename = \"0fc6e51a5ea6dea107c195591d20a1b2-15.26710677._000019.pool.root.1\"\n",
    "    pt = uproot.open(filename)['treeme'].arrays(library='ak')  # type: ignore\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can create the input layer. THis is the \"dummy\" version - with only 1 partition when we create, but want to come back during the `compute()` call and update to be 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_layer = \"SX_Query_Result\"\n",
    "\n",
    "input_layer = dak.layers.AwkwardInputLayer(\n",
    "    name=name_layer,\n",
    "    inputs=[0],\n",
    "    io_func=generate_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the high level array, we need the metadata/type info that describes the Schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[...]\n",
       "------------------------\n",
       "type: ## * {\n",
       "    JetPt: var * float64\n",
       "}</pre>"
      ],
      "text/plain": [
       "<Array-typetracer [...] type='## * {JetPt: var * float64}'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_array = ak.from_iter([\n",
    "    {\"JetPt\": [1.0, 2.1]},\n",
    "])\n",
    "type_info = dak.core.typetracer_array(sample_array)\n",
    "type_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the high level array that we can then \"query\" against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlg = dask.highlevelgraph.HighLevelGraph.from_collections(name_layer, input_layer)\n",
    "ar = dak.core.new_array_object(hlg, name_layer, meta=type_info, npartitions=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the query and run\n",
    "\n",
    "When we run this, we want it to print out:\n",
    "\n",
    "```text\n",
    "Loading data for partition 0\n",
    "Loading data for partition 1\n",
    "Loading data for partition 2\n",
    "Loading data for partition 3\n",
    "Loading data for partition 4\n",
    "Loading data for partition 5\n",
    "Loading data for partition 6\n",
    "Loading data for partition 7\n",
    "Loading data for partition 8\n",
    "Loading data for partition 9\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for partition 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>[[509, 315],\n",
       " [346, 251, 179],\n",
       " [548, 172, 166],\n",
       " [667, 505],\n",
       " [631, 278, 190],\n",
       " [406, 272, 177, 160],\n",
       " [353, 353],\n",
       " [656, 484, 183, 152],\n",
       " [225, 188],\n",
       " [486, 382],\n",
       " ...,\n",
       " [670, 577, 152],\n",
       " [709, 642, 162],\n",
       " [761, 543, 170],\n",
       " [580, 468, 171, 159],\n",
       " [320, 254, 198],\n",
       " [572, 462, 168, 160],\n",
       " [605, 545, 315],\n",
       " [571, 233, 222, 164],\n",
       " [763, 452, 270]]\n",
       "---------------------------\n",
       "type: 50000 * var * float64</pre>"
      ],
      "text/plain": [
       "<Array [[509, 315], [...], ..., [763, 452, 270]] type='50000 * var * float64'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = ar.JetPt * 5\n",
    "pt.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.awkward<multiply, npartitions=1>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing it by hand\n",
    "\n",
    "Try changing the `.inputs` by hand (`ar.npartitions` can't be set it seems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.awkward<multiply, npartitions=1>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer.inputs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for partition 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>[[509, 315],\n",
       " [346, 251, 179],\n",
       " [548, 172, 166],\n",
       " [667, 505],\n",
       " [631, 278, 190],\n",
       " [406, 272, 177, 160],\n",
       " [353, 353],\n",
       " [656, 484, 183, 152],\n",
       " [225, 188],\n",
       " [486, 382],\n",
       " ...,\n",
       " [670, 577, 152],\n",
       " [709, 642, 162],\n",
       " [761, 543, 170],\n",
       " [580, 468, 171, 159],\n",
       " [320, 254, 198],\n",
       " [572, 462, 168, 160],\n",
       " [605, 545, 315],\n",
       " [571, 233, 222, 164],\n",
       " [763, 452, 270]]\n",
       "---------------------------\n",
       "type: 50000 * var * float64</pre>"
      ],
      "text/plain": [
       "<Array [[509, 315], [...], ..., [763, 452, 270]] type='50000 * var * float64'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
