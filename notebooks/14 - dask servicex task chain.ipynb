{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DASK to ServiceX - Using a Task Chain\n",
    "\n",
    "In this demo we'll take advantage of DASK and ServiceX. This work is driven by the fact that `AwkwardInputLayer` seems like it will not take tasks as inputs. So we need to move onto something else.\n",
    "\n",
    "## Assumptions:\n",
    "\n",
    "* We don't start anything until we know the number of files that SX will produce. Thus we know the number of partitions up front.\n",
    "* We are ok with some files failing coming out of SX\n",
    "* We are going to do one partition per file\n",
    "* When we start we don't know all the _names_ of the files produced.\n",
    "* We have to fetch them from minio, and that doesn't put them in any sort of time order.\n",
    "\n",
    "## Design Outline\n",
    "\n",
    "* A single `dask` task/layer that has a single output per partition. The output is just a string, indicating the file we need to open in uproot.\n",
    "* A single thread polls ServiceX looking for new files to show up, and when they do, it passes them to a `dask` output. A `dask` task then tries to open the file.\n",
    "* We can't use a queue for the downstream tasks to grab - so we'll use a task chain.\n",
    "\n",
    "The problem:\n",
    "* `dask` is built around the idea that any task can be re-run with the exact same results.\n",
    "* In this implementation we are using a chain of tasks to emulate a distributed queue.\n",
    "* But the basic problem ends up being: the thread that inserts the items on the `queue` might be in a different process than the `task` that needs to read the `queue`.\n",
    "* `dask` points this out by refusing to pickle a lock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gordo\\Code\\iris-hep\\awkward-20-testing\\.venv\\Lib\\site-packages\\distributed\\node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 64850 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import dask_awkward as dak\n",
    "import awkward as ak\n",
    "import dask\n",
    "import uproot\n",
    "\n",
    "from dask.highlevelgraph import Layer, HighLevelGraph\n",
    "from dask.distributed import Client, LocalCluster\n",
    "from typing import AbstractSet\n",
    "\n",
    "import logging\n",
    "\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "\n",
    "# Make debugging a little easier...\n",
    "cluster = LocalCluster(processes=False)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `uproot.dask` getting the form info\n",
    "\n",
    "Eventually this gets built from scratch and the query. But lets not worry about that now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `awkward.Form` file form\n",
    "\n",
    "We need the form from the schema to prevent us from having to open files that do not yet exist in hour hack. Eventually we'll have to build this from the schema we know exists from the `func_adl` query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RecordForm([ListOffsetForm('i64', NumpyForm('float64'))], ['JetPt']),\n",
       " <Array-typetracer [...] type='## * {JetPt: var * float64}'>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_filename = \"0fc6e51a5ea6dea107c195591d20a1b2-15.26710677._000019.pool.root.1\"\n",
    "with uproot.open(dummy_filename) as file:\n",
    "    file_form = file['treeme'].arrays().layout.form\n",
    "    metadata = dak.core.typetracer_array(file['treeme'].arrays())\n",
    "\n",
    "file_form, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>[[102, 63.1],\n",
       " [69.3, 50.2, 35.7],\n",
       " [110, 34.5, 33.1],\n",
       " [133, 101],\n",
       " [126, 55.7, 38],\n",
       " [81.1, 54.4, 35.3, 32],\n",
       " [70.6, 70.5],\n",
       " [131, 96.9, 36.6, 30.5],\n",
       " [45.1, 37.6],\n",
       " [97.2, 76.4],\n",
       " ...,\n",
       " [134, 115, 30.4],\n",
       " [142, 128, 32.5],\n",
       " [152, 109, 34.1],\n",
       " [116, 93.6, 34.2, 31.9],\n",
       " [64, 50.8, 39.5],\n",
       " [114, 92.4, 33.6, 32],\n",
       " [121, 109, 63.1],\n",
       " [114, 46.6, 44.4, 32.9],\n",
       " [153, 90.5, 54]]\n",
       "---------------------------\n",
       "type: 50000 * var * float64</pre>"
      ],
      "text/plain": [
       "<Array [[102, 63.1], [...], ..., [153, 90.5, 54]] type='50000 * var * float64'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ar = uproot.dask({dummy_filename: \"treeme\"}, open_files=False, known_base_form=file_form)\n",
    "test_ar.JetPt.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Task Chain\n",
    "\n",
    "Create a layer that emulates pulling data off SX.\n",
    "\n",
    "We will emulate the return from SX via the `sd_filelist` - this will contains all the files that we'd ask SX for return from a query. We'll use dummy files to keep ourselves \"sane\" but will always access `dummy_filename` in the end b.c. that is the actual file we have locally in this repo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_filename = \"0fc6e51a5ea6dea107c195591d20a1b2-15.26710677._000019.pool.root.1\"\n",
    "sd_filelist = [\n",
    "    f\"file_{i}\" for i in range(5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import multiprocessing\n",
    "import time\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "class SXFileFetcher(Layer):\n",
    "    '''Grab new files from SX and if they haven't been assigned, assign one to our output. Also pass on\n",
    "    the list of all assigned files so the next step knows what files haven't been assigned yet.\n",
    "\n",
    "    * If we are the first, then we do not need to wait for any dependencies\n",
    "    '''\n",
    "    def __init__(self, name: str, previous_output: Optional[str] = None):\n",
    "        '''Wait for at least one new file to become available from SX. Send it out in the output.\n",
    "\n",
    "        Args:\n",
    "            name (str): Name of the basics for the fetch. The actual layer name will be this plus the file number.\n",
    "            previous_output (str): The name of the previous output. If None, then we are the first and do not need to wait for any dependencies.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "\n",
    "        self.tasks = {}\n",
    "        if previous_output is None:\n",
    "            self.tasks[self.name] = (self.fetch_file,)\n",
    "        else:\n",
    "            self.tasks = {name: (self.fetch_file, previous_output)}\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.tasks[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.tasks)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tasks)\n",
    "\n",
    "    def is_materialized(self):\n",
    "        return False\n",
    "    \n",
    "    def get_output_keys(self) -> AbstractSet[str | bytes | int | float]:\n",
    "        return set(self.tasks.keys())\n",
    "    \n",
    "    def fetch_file(self, previous_result: Tuple[str, List[str]] = (\"\", [])) -> Tuple[str, List[str]]:\n",
    "        '''Fetch a file from SX and return it along with the list of all files that have been assigned so far.\n",
    "\n",
    "        Args:\n",
    "            previous_result (Tuple[str, List[str]]): The previous result. If None, then we are the first.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[str, List[str]]: The file that was fetched and the list of all files that have been assigned so far.\n",
    "        '''\n",
    "        # Get the result from SX and then look for a new file.\n",
    "        _, all_started_files = previous_result\n",
    "        started_files = set(all_started_files)\n",
    "\n",
    "        sx_files = set(sd_filelist)\n",
    "        new_files = sx_files - started_files\n",
    "\n",
    "        assert len(new_files) > 0, \"No new files, but should be - in reality we would now poll SX\"\n",
    "        new_file = new_files.pop()\n",
    "\n",
    "        # Now, build the info we pass on down.\n",
    "        return (new_file, all_started_files + [new_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the layer that will load files from the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URLoaderLayer(Layer):\n",
    "    def __init__(self, name, sx_layer_name, output_names):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        # self.dependencies = {name: sx_layer_name}\n",
    "        self.tasks = {\n",
    "            (name, i): (lambda file_name: self.get_data(file_name), f'{f_name}')\n",
    "            for i, f_name in enumerate(output_names)\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.tasks[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.tasks)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tasks)\n",
    "\n",
    "    def is_materialized(self):\n",
    "        return False\n",
    "    \n",
    "    def get_output_keys(self) -> AbstractSet[str | bytes | int | float]:\n",
    "        return set(self.tasks.keys())\n",
    "    \n",
    "    def get_data(self, file_info: Tuple[str, List[str]]) -> ak.Array:\n",
    "        '''Return the info that is needed by uproot to actually open the file'''\n",
    "        # This message swallowed unless we use a dask `LocalCluster` (use it for debugging)\n",
    "        logging.warning(f\"Returning info for file {file_info[0]}\")\n",
    "        with uproot.open(dummy_filename) as file:\n",
    "            return file[\"treeme\"].arrays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know ahead of time how many \"files\" there are in a query - so we can use that to build up all those layers that do the task chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The layers that will each pick off a file.\n",
    "n_files_in_sx_query = len(sd_filelist)\n",
    "file_finder_layers = [\n",
    "    SXFileFetcher(f\"sx_fetcher_{i}\", f\"sx_fetcher_{i-1}\" if i > 0 else None)\n",
    "    for i in range(n_files_in_sx_query)\n",
    "]\n",
    "output_names = [s for ss in file_finder_layers for s in ss.get_output_keys()]\n",
    "assert len(output_names) == n_files_in_sx_query, \"We should have one output per file finder layer\"\n",
    "\n",
    "# The layer that does the loading has to be hooked up to all these previous layers.\n",
    "loader_layer = URLoaderLayer(\"uproot_loader\", \"ur-loader-layer\", output_names)\n",
    "\n",
    "# Now, the high level layer...\n",
    "hlg = HighLevelGraph(\n",
    "    layers={f.name: f for f in file_finder_layers + [loader_layer]},\n",
    "    dependencies={\n",
    "        **{loader_layer.name: {s.name for s in file_finder_layers}},\n",
    "        **{s.name: set() for s in file_finder_layers}\n",
    "    }\n",
    ")\n",
    "\n",
    "# And finally the array...\n",
    "ar = dak.core.new_array_object(hlg, \"uproot_loader\", meta=metadata, npartitions=n_files_in_sx_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Returning info for file file_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Returning info for file file_4\n",
      "WARNING:root:Returning info for file file_2\n",
      "WARNING:root:Returning info for file file_1\n",
      "WARNING:root:Returning info for file file_0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>[[102],\n",
       " [],\n",
       " [110],\n",
       " [133, 101],\n",
       " [126],\n",
       " [],\n",
       " [],\n",
       " [131],\n",
       " [],\n",
       " [],\n",
       " ...,\n",
       " [134, 115],\n",
       " [142, 128],\n",
       " [152, 109],\n",
       " [116],\n",
       " [],\n",
       " [114],\n",
       " [121, 109],\n",
       " [114],\n",
       " [153]]\n",
       "----------------------------\n",
       "type: 250000 * var * float64</pre>"
      ],
      "text/plain": [
       "<Array [[102], [], [110], ..., [114], [153]] type='250000 * var * float64'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar.JetPt[ar.JetPt > 100.0].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsides\n",
    "\n",
    "This will work. Some issues...\n",
    "\n",
    "* The SX query will be made from anywhere in the cluster. So the user's `servicex.yaml` file will need to be available everywhere. Or it would have to be made available in every client.\n",
    "* With 1000's of files, you'll get tuples that are 1000 URL's long being passed around inside of DASK (about 150Kb max, I would guess).\n",
    "\n",
    "But some really nice things:\n",
    "\n",
    "* The data load from `minio` will be from across the cluster - no single machine will be doing this - so a very distributed way to load the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
